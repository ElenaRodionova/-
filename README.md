# Классификация твитов covid_fake_news на фейковые/истинные.

Обнаружение поддельных новостей COVID-19 на английском языке 

# Описание задачи
Это подзадача в общей задаче CONSTRAINT-2021 по обнаружению враждебных сообщений. Эта подзадача направлена на обнаружение поддельных новостей, связанных с COVID19, на английском языке. Источниками данных являются различные платформы социальных сетей, такие как Twitter, Facebook, Instagram и т.д. Учитывая публикацию в социальных сетях, цель общего задания состоит в том, чтобы классифицировать ее либо на фейковые, либо на реальные новости.

В работе https://github.com/diptamath/covid_fake_news были иследованы различные языковые модели, такие как XLNet, RoBERTa, XLM-RoBERTa, DeBERTa, ELECTRA и ERNIE2.0. Были опробованы различные методы объединения, используя различные комбинации этих моделей. Комбинация, которая дала наилучший результат, - это комбинация с использованием XLNet, RoBERTa, XLM-RoBERTa, DeBERTa. В работе создан новый набор функций, используя прогнозы из разных моделей прогнозирования, и сохранены полученные данные о функциях, оопробованы 2 метода объединения: жесткое голосование и мягкое голосование, где мягкое голосование дало превосходные результаты при использовании вышеуказанной комбинации моделей. 

## Важность определения фейковых новостей важно по нескольким причинам:

1. Защита от манипуляции: Фейковые новости могут быть использованы для манипуляции общественным мнением, формирования негативного отношения к определенным людям или организациям, или даже для вызова паники. Определение фейковых новостей помогает избежать этих негативных последствий.

2. Сохранение доверия к СМИ: Если люди не могут доверять информации, которую они получают от СМИ, это может привести к распространению недоверия к официальным источникам информации. Определение фейковых новостей помогает сохранить доверие к СМИ.

3. Борьба с дезинформацией: Фейковые новости могут создавать конфликты, разрушать общественный мир, и приводить к неправильным решениям. Определение фейковых новостей помогает бороться с дезинформацией и сохранять целостность общества. 

В целом, определение фейковых новостей важно для обеспечения сохранности информационной среды, защиты демократии и сохранения доверия к официальным источникам информации.

### Результаты работы https://github.com/diptamath/covid_fake_news
В работе авторы получили оценку F1 в 98,83 балла, используя эвристическую постобработку.

Целью данной работы является сравнение результатов, полученных в работе,:

1. Что будет, если использовать самый наивный метод (CountVectorizer)? А если векторизатор Tf-Idf.
2. Как изменятся показатели, если использовать нормализацию?
3. На сколько наивный метод (GaussianNB) и классический метод для классификации (LogisticRegression) покажут результататы хуже XLNet, RoBERTa, XLM-RoBERTa, DeBERTa, ELECTRA и ERNIE2.0. 

## Задача
1) Использовать несколько векторизаций (CountVectorizer/Tf-Idf)
2) Провести тесты с нормализацией (Stemming/Lemmatization) и без
3) Использовать несколько моделей (GaussianNB/LogisticRegression)
4) Анализ ошибок (метрики/ConfusionMatrix)

# Полученные результаты и выводы

1) С векторизацией CountVectorizer без использования обработки LogisticRegression показала результат лучше, чем GaussianNB.
2) С векторизацией Tf-Idf без использования обработки LogisticRegression показала результат лучше, чем GaussianNB.
3) Использование Stemming и Lemmatization при векторизации CountVectorizer  значительно ухудшило результаты LogisticRegression и практически не повлияло на результаты GaussianNB.
4) Использование Stemming и Lemmatization при векторизации Tf-Idf  практически не повлияло на результаты как LogisticRegression,  так и GaussianNB.
5) Лучший результат 0.92 получился при векторизации Tf-Idf с использованием модели LogisticRegression. При этом доля ошибок вида False Negative составляет 8.5%, а доля ошибок вида False Positive составляет 7.6%. Что достаточно неплохой результат.
